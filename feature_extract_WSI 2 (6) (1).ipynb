{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Created and Updated on Mon Aug 16th 2021\n",
    "\n",
    "@author: Rakesh Choudhary\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook documents the WSI feature extraction process.\n",
    "\n",
    "Briefly the steps are:\n",
    "\n",
    "**WSI and Tissue Processing**\n",
    "\n",
    "1. Connecting to HistomicsTK\n",
    "2. Perform the Tissue Detection and identification of unique tissue areas\n",
    "\n",
    "**Obtain Geometry Files**\n",
    "\n",
    "3. Extract geometry, merge the polygons and save the geometry file required for feature extraction, if no tissue separation required directly jump to step 7 and eliminate the triangles crossing the MT boundary\n",
    "4. Perform the cutting of triangles if there are multiple tissue slices on the WSI\n",
    "5. Apply Network Graphx to find the individual objects located in the two tissue slices\n",
    "6. Use the object list obtained from the above step to apply heuristics and obtain Main Tumor and Satellite regions for the respective tissue slices\n",
    "\n",
    "**Architectural Feature Extraction**\n",
    "\n",
    "7. Using the geom file, extract the initial set of Delaunay Features\n",
    "8. Calculate the Delaunay and Satellite Distance features for the separated Tissue Slices and ask Dr. Doyle if we require convex hull features\n",
    "9. Save the feature values in a Pandas data frame\n",
    "10. Upload these features back on HistomicsTk for visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Imports Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src/utils')\n",
    "#from pathlib import Path \n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.tri as T\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "from skimage import data\n",
    "from skimage.color import rgb2hsv\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import girder_client\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from skimage import segmentation, color\n",
    "from skimage.morphology import erosion, disk, opening, remove_small_objects\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance, ConvexHull, Delaunay\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from histomicstk.saliency.tissue_detection import (\n",
    "    get_slide_thumbnail, get_tissue_mask)\n",
    "\n",
    "from histomicstk.annotations_and_masks.masks_to_annotations_handler import (\n",
    "    get_annotation_documents_from_contours\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htk_utils import (\n",
    "    get_histomics_connection, \n",
    "    get_sample_id,\n",
    "    get_annotations_from_htk\n",
    ")\n",
    "\n",
    "from geom_utils import (\n",
    "    get_polygon_from_cords,\n",
    "    get_edge_cordinates,\n",
    "    get_centroid_cordinates,\n",
    "    cut_triangles\n",
    ")\n",
    "\n",
    "from feature_utils import (\n",
    "    get_triangle_lengths,\n",
    "    get_triangle_areas,\n",
    "    descriptive_stats,\n",
    "    assign_wave_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sunycell import dsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Histomics / DSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load secrets\n",
    "load_dotenv(dotenv_path='api.env')\n",
    "APIURL = os.getenv('APIURL')\n",
    "APIKEY = os.getenv('APIKEY')\n",
    "\n",
    "# Get connection\n",
    "conn = get_histomics_connection(APIURL, APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_id(coll,conn):\n",
    "    coll_list=conn.get(\"collection?text=\"+coll+\"limit=50&sort=name&sortdir=1\")\n",
    "    coll_id=None\n",
    "    for folder in coll_list:\n",
    "        coll_id = folder['_id'] \n",
    "    return coll_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_list = get_collection_id(\"Oral Cavity Cancer\", conn)\n",
    "coll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_id(folder_name,conn,collection_id):\n",
    "    folder_id = None\n",
    "    folder_list = conn.listFolder(collection_id, parentFolderType = \"collection\")\n",
    "    for folder in folder_list:\n",
    "        if folder['name'] == folder_name:\n",
    "            folder_id = folder['_id']\n",
    "    return folder_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_id(sample_name,conn,collection_name,folder_name):\n",
    "    collection_id = get_collection_id(collection_name,conn)\n",
    "    folder_id = get_folder_id(folder_name,conn,collecion_id)\n",
    "    sample_id = None\n",
    "    item_list = conn.listItem(folder_id)\n",
    "    for item in item_list:\n",
    "        if item['name']==sample_name:\n",
    "            sample_id=item['_id']\n",
    "    return sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = get_collection_id('Oral Cavity Cancer', conn)\n",
    "folder_id = get_folder_id('NMHS-Finished', conn, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of slides\n",
    "item_id_list = conn.listItem(folder_id)\n",
    "\n",
    "slide_ids  = []\n",
    "slide_names = []\n",
    "for l in item_id_list:\n",
    "    slide_ids.append(l['_id'])\n",
    "    slide_names.append(l['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make holder directory for features\n",
    "feature_dir = 'features_csv'\n",
    "os.makedirs(feature_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-slide test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 4:\n",
    "# OCC-02-0004-01Z-03-O01.tiff_0 = 27\n",
    "# OCC-05-0009-01Z-01-O01.tiff_0 = 132\n",
    "# OCC-03-0021-01Z-01-O01.tiff_0 = 66\n",
    "# OCC-03-0005-01Z-02-O01.tiff_0 = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottom 3:\n",
    "# OCC-02-0005-01Z-01-O01.tiff_0 = 29\n",
    "# OCC-02-0018-01Z-02-O01.tiff_0 = 45\n",
    "# OCC-03-0035-01Z-02-O01.tiff_0 = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_id = slide_ids[18]\n",
    "slide_name = slide_names[18]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a thumbnail of the image\n",
    "try:\n",
    "    thumbnail_rgb = get_slide_thumbnail(conn, slide_id)\n",
    "except:\n",
    "    print(f'Could not extract thumbnail for {slide_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgb_img = thumbnail_rgb\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "\n",
    "plt.imshow(rgb_img)\n",
    "plt.title(\"RGB image\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.savefig( slide_name + 'Thumbnail.png', dpi=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(thumb_height, thumb_width, _) = np.shape(thumbnail_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_img = rgb2hsv(thumbnail_rgb)\n",
    "hue_img = hsv_img[:, :, 0]\n",
    "value_img = hsv_img[:, :, 2]\n",
    "saturation_img= hsv_img[:,:, 1]\n",
    "\n",
    "fig, (ax0, ax1,) = plt.subplots(ncols=2, figsize=(20,10))\n",
    "\n",
    "ax0.imshow(thumbnail_rgb)\n",
    "ax0.set_title(\"RGB image\")\n",
    "ax0.axis('off')\n",
    "\n",
    "ax1.imshow(hsv_img[:, :, 1], cmap = plt.cm.gray)\n",
    "ax1.set_title(\"Saturation_channel\")\n",
    "ax1.axis('off')\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh_img = saturation_img\n",
    "threshold = 0.2\n",
    "binary_img = thresh_img > np.max(thresh_img)*(threshold)\n",
    "\n",
    "selem = disk(1)\n",
    "mask_proc = opening(binary_img, selem)\n",
    "mask_proc = ndi.binary_fill_holes(mask_proc>0)\n",
    "\n",
    "mask_proc = remove_small_objects(mask_proc, min_size = 1000)\n",
    "labeled_proc = label(mask_proc, background = 0)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20,10))\n",
    "\n",
    "ax0.imshow(binary_img)\n",
    "ax0.set_title(\"Thresholded image\")\n",
    "ax0.axis('off')\n",
    "\n",
    "ax1.imshow(labeled_proc)\n",
    "ax1.set_title(\"Filled image\")\n",
    "ax1.axis('off')\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selem = disk(1)\n",
    "mask_proc = opening(binary_img, selem)\n",
    "plt.imshow(mask_proc)\n",
    "mask_proc = ndi.binary_fill_holes(mask_proc>0)\n",
    "\n",
    "f, ax = plt.subplots(1, 4, figsize=(20, 20))\n",
    "ax[0].imshow(binary_img)\n",
    "ax[1].imshow(mask_proc, cmap=plt.cm.gray)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_proc = remove_small_objects(mask_proc, min_size = 1000)\n",
    "labeled_proc = label(mask_proc, background = 0)\n",
    "plt.imshow(labeled_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tissue_boundary(img, threshold = 0.07):\n",
    "  \n",
    "    # Convert to HSV\n",
    "    hsv_img = rgb2hsv(img)\n",
    "    \n",
    "    # Split the channels\n",
    "    hue_img = hsv_img[:, :, 0]\n",
    "    saturation_img= hsv_img[:,:, 1]\n",
    "    value_img = hsv_img[:, :, 2]\n",
    "    \n",
    "    # Threshold the saturation channel\n",
    "    thresh_img = saturation_img\n",
    "    binary_img = thresh_img > np.max(thresh_img)*threshold\n",
    "\n",
    "    # Run binary opening\n",
    "    selem = disk(1)\n",
    "    mask_proc = opening(binary_img, selem)\n",
    "    \n",
    "    #plt.imshow(mask_proc)\n",
    "    # Fill holes\n",
    "    mask_proc = ndi.binary_fill_holes(mask_proc>0)\n",
    "    labeled_proc = label(mask_proc, background = 0)\n",
    "    \n",
    "    return labeled_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img = detect_tissue_boundary(thumbnail_rgb, threshold = 0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the image and detected boundary\n",
    "\n",
    "f, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "ax[0].imshow(thumbnail_rgb)\n",
    "ax[1].imshow(labeled_img)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the largest object in the image\n",
    "largestCC = labeled_img == np.argmax(np.bincount(labeled_img.flat)[1:]) + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the image and detected boundary\n",
    "\n",
    "f, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "ax[0].imshow(thumbnail_rgb)\n",
    "ax[1].imshow(largestCC)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find tissue boundaries and scale their coordinates\n",
    "\n",
    "The tissue boundary coordinates need to be scaled to the full image size; so here we figure out how much to multiply each coordinate by.\n",
    "\n",
    "This will allow us to perform feature extraction / graph creation in the original WSI coordinate space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the x and y coordinates of the tissue regions\n",
    "def get_tissue_coordinates(labeled_img):\n",
    "    img_tissue_boundary = segmentation.find_boundaries(labeled_img)\n",
    "    print(np.shape(labeled_img))\n",
    "    \n",
    "    (tissue_y, tissue_x) = np.nonzero(img_tissue_boundary)\n",
    "    print(f'Image_boundary {np.shape(img_tissue_boundary)}')\n",
    "\n",
    "    tissue_x = (tissue_x).astype(float)\n",
    "    tissue_y = (tissue_y).astype(float)\n",
    "    return tissue_x, tissue_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tissue_boundaries(labeled_img):\n",
    "    \n",
    "    # Get the list of labels for this class\n",
    "    objs = np.unique(labeled_img)\n",
    "    \n",
    "    obj_bounds = []\n",
    "\n",
    "    for obj in objs[1:]:\n",
    "        # Grab a binary image containing only the current object\n",
    "        this_obj = labeled_img == obj\n",
    "        \n",
    "        # Pad by 1 -- need to operate correctly at the boundaries\n",
    "        this_obj = np.pad(this_obj, 1, 'constant', constant_values=0)\n",
    "\n",
    "        # Use the contour function to grab the boundary points IN CORRECT ORDER\n",
    "        # The order of the contour points is important; Histomics will freak out\n",
    "        # if the points are not in \"marching\" order around the boundary\n",
    "        cnt = plt.contour(this_obj)\n",
    "        pts = cnt.collections[0].get_paths()[0].vertices\n",
    "\n",
    "        obj_bounds.append(pts)\n",
    "    \n",
    "    return obj_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tissue_x, tissue_y = get_tissue_coordinates(labeled_img)\n",
    "tissue_bounds = get_tissue_boundaries(largestCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unravel tissue bounds to get all X's and Y's\n",
    "tissue_x = []\n",
    "tissue_y = []\n",
    "for tissue_bound in tissue_bounds:\n",
    "    for a in tissue_bound:\n",
    "        tissue_x.append(a[0])\n",
    "        tissue_y.append(a[1])\n",
    "num_pts = len(tissue_x)\n",
    "\n",
    "\n",
    "# gets every 3 points of tissue coordinates\n",
    "tissue_x = np.array(tissue_x[::3])\n",
    "tissue_y = np.array(tissue_y[::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_info = conn.get(f\"/item/{slide_id}/tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slide_ratio(slide_info, thumb_height, thumb_width):\n",
    "    slide_width = slide_info['sizeX']\n",
    "    slide_height = slide_info['sizeY']\n",
    "\n",
    "    height_ratio = slide_height / thumb_height\n",
    "    width_ratio = slide_width / thumb_width\n",
    "    \n",
    "    return height_ratio, width_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_ratio, width_ratio = get_slide_ratio(slide_info, thumb_height, thumb_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_x = list((width_ratio * tissue_x).astype(int))\n",
    "tissue_y = list((height_ratio * tissue_y).astype(int))\n",
    "\n",
    "\n",
    "tissue_cordinates = [[x,y] for x,y in zip (tissue_x, tissue_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements, metadata = get_annotations_from_htk(conn, slide_id, group_list=['tumor', 'ai_tumor', 'satellite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_coordinates(elements):\n",
    "    coords = []\n",
    "    for idx, element in enumerate(elements):\n",
    "        points = element['points']\n",
    "        points = [x[:-1] for x in points]\n",
    "        \n",
    "        X = np.array([int(p[0]) for p in points], dtype=np.int64)\n",
    "        Y = np.array([int(p[1]) for p in points], dtype=np.int64)\n",
    "        \n",
    "        coords.append([X, Y])\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_from_coords(coords):\n",
    "    polygons = []\n",
    "    for coord in coords:\n",
    "        X = coord[0]\n",
    "        Y = coord[1]\n",
    "        point_list = [(x,y) for x,y in zip(X,Y)]\n",
    "        poly = Polygon(point_list)\n",
    "        polygons.append(poly)\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_objects(elements):\n",
    "    # Get the edges of the polygons and merge those which are overlapping\n",
    "    poly_edges = get_edge_cordinates(elements)\n",
    "    polygon_objects = get_polygon_from_cords(poly_edges)\n",
    "    poly_union = unary_union(polygon_objects)\n",
    "    print(type(poly_union))\n",
    "    \n",
    "    # Calculate the centroids of all the unified polygons\n",
    "    polygon_centroids = np.array([0, 0])\n",
    "    if type(poly_union) == Polygon:\n",
    "        print('True')\n",
    "        x,y = poly_union.centroid.xy\n",
    "        polygon_centroids = np.vstack([polygon_centroids, [x[0], y[0]]])\n",
    "    else:\n",
    "\n",
    "        \n",
    "        for poly in poly_union:\n",
    "            x,y = poly.centroid.xy\n",
    "            polygon_centroids = np.vstack([polygon_centroids, [x[0], y[0]]])\n",
    "    polygon_centroids = polygon_centroids[1:]\n",
    "    return poly_union, polygon_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_union, polygon_centroids = get_polygon_objects(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut the polygons into neighborhoods\n",
    "\n",
    "The process here:\n",
    "\n",
    "1. Construct DT\n",
    "2. Break the branches that cross tissue coordinates\n",
    "3. Process each neighborhood to create a unique geometry file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct DT\n",
    "tri = Delaunay(polygon_centroids)\n",
    "#tri_simplices_cut = cut_triangles(tri, tissue_cordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], tri.simplices, c='r')\n",
    "ax.scatter(polygon_centroids[:,0], polygon_centroids[:,1], c='g')\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "ax.axis('off')\n",
    "plt.savefig( slide_name + 'Initial_Delaunay.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], tri.simplices, c='r')\n",
    "ax.scatter(polygon_centroids[:,0], polygon_centroids[:,1], c='g')\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "\n",
    "plt.xlim(13000, 19500)\n",
    "plt.ylim(5000, 12000)\n",
    "\n",
    "#plt.savefig( slide_name + 'Initial_Delaunay.png', dpi=100)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tissue_cordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tissue_cordinates = sorted(tissue_cordinates)\n",
    "tissue_cordinates=np.array(tissue_cordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(p1, p3, p4):\n",
    "    diff13 = np.subtract(p1, p3)\n",
    "    diff43 = np.subtract(p4, p3)\n",
    "\n",
    "    return np.cross(diff13, diff43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_segment(p1, p2, p):\n",
    "    return min(p1[0], p2[0]) <= p[0] <= max(p1[0], p2[0]) and min(p1[1], p2[1]) <= p[1] <= max(p1[1], p2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_intersection(pt1, pt2, pt3, pt4):\n",
    "    \"\"\"Check whether the lines represented by pt1->pt2 and pt3->pt4 \"\"\"\n",
    "    d1 = direction(pt1, pt3, pt4)\n",
    "    d2 = direction(pt2, pt3, pt4)\n",
    "\n",
    "    d3 = direction(pt3, pt1, pt2)\n",
    "    d4 = direction(pt4, pt1, pt2)\n",
    "\n",
    "    if ((d1 > 0 and d2 < 0) or (d1 < 0 and d2 > 0)) and \\\n",
    "        ((d3 > 0 and d4 < 0) or (d3 < 0 and d4 > 0)):\n",
    "        return True\n",
    "    elif d1 == 0 and on_segment(pt3, pt4, pt1):\n",
    "        return True\n",
    "    elif d2 == 0 and on_segment(pt3, pt4, pt2):\n",
    "        return True\n",
    "    elif d3 == 0 and on_segment(pt1, pt2, pt3):\n",
    "        return True\n",
    "    elif d4 == 0 and on_segment(pt1, pt2, pt4):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pt1 = np.array([0, 0])\n",
    "pt2 = np.array([1, .6])\n",
    "\n",
    "pt3 = np.array([0, 0])\n",
    "pt4 = np.array([1.1, 1])\n",
    "\n",
    "f,a = plt.subplots(figsize=(10,10))\n",
    "\n",
    "a.plot([pt1[0], pt2[0]], [pt1[1], pt2[1]], 'k')\n",
    "a.plot([pt3[0], pt4[0]], [pt3[1], pt4[1]], 'r')\n",
    "\n",
    "a.text(pt1[0], pt1[1], 'Pt 1')\n",
    "a.text(pt2[0], pt2[1], 'Pt 2')\n",
    "a.text(pt3[0], pt3[1], 'Pt 3')\n",
    "a.text(pt4[0], pt4[1], 'Pt 4')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "check_intersection(pt1, pt2, pt3, pt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2\n",
    "# create a list of lines for each pair of tissue coordinate\n",
    "tissue_lines = []\n",
    "end  = len(tissue_cordinates)-1\n",
    "for idx in np.arange(len(tissue_cordinates)):\n",
    "    if idx == 0:\n",
    "        this_line = [tissue_cordinates[end], tissue_cordinates[idx]]\n",
    "    else:\n",
    "        this_line = [tissue_cordinates[idx-1], tissue_cordinates[idx]]\n",
    "        \n",
    "    tissue_lines.append(this_line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tissue coordinates that you are sure have DT intersection\n",
    "#test_tissue_lines = tissue_lines[1000:1800]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], tri.simplices, c='b')\n",
    "ax.scatter(polygon_centroids[:,0], polygon_centroids[:,1], c='g')\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "for test_line in tissue_lines:\n",
    "    ax.plot(\n",
    "        [test_line[0][0], test_line[1][0]], \n",
    "        [test_line[0][1], test_line[1][1]], 'r')\n",
    "ax.axis('off')\n",
    "\n",
    "#plt.xlim(13000, 19500)\n",
    "#plt.ylim(5000, 12000)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cut triangles before performing the check intersection for WSI that contains large amounts of annotation.\n",
    "\n",
    "#tri_simplices_cut = cut_triangles(tri.simplices, tissue_cordinates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 3\n",
    "# Create lines using triangle points\n",
    "\n",
    "cut_triangles = []\n",
    "\n",
    "for idx, t in enumerate(tri.simplices):\n",
    "    p1 = polygon_centroids[t[0], :]\n",
    "    p2 = polygon_centroids[t[1], :]\n",
    "    p3 = polygon_centroids[t[2], :]\n",
    "    \n",
    "    line1 = [np.array([p1[0], p1[1]]), np.array([p2[0], p2[1]])]   \n",
    "    line2 = [np.array([p2[0], p2[1]]), np.array([p3[0], p3[1]])]\n",
    "    line3 = [np.array([p3[0], p3[1]]), np.array([p1[0], p1[1]])]    \n",
    "    \n",
    "    edges = [line1, line2, line3]\n",
    "\n",
    "    for edge in edges:\n",
    "        is_intersected = False\n",
    "        #print(f'Edge: {edge}')\n",
    "        \n",
    "        for tissue_line in tissue_lines:\n",
    "            #print(f'Tissue Line: {tissue_line}')\n",
    "            \n",
    "            #for p1, p2 in edge[0], edge[1]:\n",
    "            #    for p3, p4 in tissue_line:\n",
    "            #        print(f'Checking: p1 = {p1}, p2 = {p2}, p3 = {p3}, p4 = {p4}')\n",
    "            if check_intersection(edge[0], edge[1], tissue_line[0], tissue_line[1]) == True:\n",
    "                #print(f'Found an intersection!')\n",
    "\n",
    "                is_intersected = True\n",
    "                if idx not in cut_triangles:\n",
    "                    cut_triangles.append(idx)\n",
    "                        \n",
    "            if is_intersected ==True:\n",
    "                continue     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cut_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tri.simplices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#type(tri.simplices)\n",
    "\n",
    "tri_simplices = (tri.simplices).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://thispointer.com/python-remove-elements-from-list-by-index/\n",
    "\n",
    "def delete_multiple_element(list_object, indices):\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    for idx in indices:\n",
    "        if idx < len(list_object):\n",
    "            list_object.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_tri = cut_triangles  # idx of the triangles that need to be eliminated from triagnles\n",
    "\n",
    "triangles = tri_simplices\n",
    "\n",
    "delete_multiple_element(triangles, cut_tri)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the cutting\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], triangles, c='r')\n",
    "ax.scatter(polygon_centroids[:,0], polygon_centroids[:,1], c='g')\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "ax.axis('off')\n",
    "plt.savefig( slide_name + 'Cut_Delaunay.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], triangles, c='b')\n",
    "ax.scatter(polygon_centroids[:,0], polygon_centroids[:,1], c='g')\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "ax.scatter(tissue_x, tissue_y)\n",
    "for test_line in tissue_lines:\n",
    "    ax.plot(\n",
    "        [test_line[0][0], test_line[1][0]], \n",
    "        [test_line[0][1], test_line[1][1]], 'r')\n",
    "ax.axis('off')\n",
    "\n",
    "#plt.xlim(13000, 19500)\n",
    "#plt.ylim(5000, 12000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], triangles, c='b')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_lengths = get_triangle_lengths(polygon_centroids, triangles)\n",
    "dt_areas = get_triangle_areas(polygon_centroids, triangles)\n",
    "dt_lengths_feats = descriptive_stats(dt_lengths, 'delaunay_length_')\n",
    "dt_areas_feats = descriptive_stats(dt_areas, 'delaunay_area_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dt_areas = sum(dt_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dt_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload features to SUNY CELL WSI Folder\n",
    "\n",
    "\n",
    "\n",
    "def create_delaunay_dataframe(nodes, simplices, group_name='Delaunay Triangulation', color_string='rgb(0,0,0)'):\n",
    "    group = []\n",
    "    color = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    has_holes = []\n",
    "    touches_edge_top = []\n",
    "    touches_edge_left = []\n",
    "    touches_edge_bottom = []\n",
    "    touches_edge_right = []\n",
    "    coords_x = []\n",
    "    coords_y = []\n",
    "\n",
    "    for simplex in simplices:\n",
    "        # Grab the coordinates of the triangle\n",
    "        obj_x = nodes[simplex, 0]\n",
    "        obj_y = nodes[simplex, 1]\n",
    "\n",
    "        # =========\n",
    "        # Possibly need to check that these should be str(int(x)) and str(int(y))?\n",
    "        obj_x_str = ','.join([str(int(x)) for x in obj_x])\n",
    "        obj_y_str = ','.join([str(int(y)) for y in obj_y])\n",
    "        # =========\n",
    "\n",
    "        ymin.append(int(np.min(obj_y)))\n",
    "        xmin.append(int(np.min(obj_x)))\n",
    "        ymax.append(int(np.max(obj_y)))\n",
    "        xmax.append(int(np.max(obj_x)))\n",
    "\n",
    "        coords_x.append(obj_x_str)\n",
    "        coords_y.append(obj_y_str)\n",
    "\n",
    "        # Properties of the overall class group (Delaunay)\n",
    "        group.append(group_name)\n",
    "        color.append(color_string)\n",
    "\n",
    "        has_holes.append(0)\n",
    "        touches_edge_top.append(0)\n",
    "        touches_edge_left.append(0)\n",
    "        touches_edge_bottom.append(0)\n",
    "        touches_edge_right.append(0)\n",
    "\n",
    "    # Put it all into a dataframe\n",
    "    return pd.DataFrame({\n",
    "        'group': group,\n",
    "        'color': color,\n",
    "        'ymin': ymin,\n",
    "        'ymax': ymax,\n",
    "        'xmin': xmin,\n",
    "        'xmax': xmax,\n",
    "        'has_holes': has_holes,\n",
    "        'touches_edge-top': touches_edge_top,\n",
    "        'touches_edge-left': touches_edge_left,\n",
    "        'touches_edge-bottom': touches_edge_bottom,\n",
    "        'touches_edge-right': touches_edge_right,\n",
    "        'coords_x': coords_x,\n",
    "        'coords_y': coords_y\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delaunay_df = create_delaunay_dataframe(polygon_centroids, triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "annprops = {\n",
    "'X_OFFSET': 0,\n",
    "'Y_OFFSET': 0,\n",
    "'opacity': 0.2,\n",
    "'lineWidth': 4.0,\n",
    "}\n",
    "annotation_docs = get_annotation_documents_from_contours(\n",
    "delaunay_df.copy(),\n",
    "separate_docs_by_group=True,\n",
    "annots_per_doc=200,\n",
    "docnamePrefix='Delaunay_triangulation',\n",
    "annprops=annprops,\n",
    "verbose=False,\n",
    "monitorPrefix=slide_names[0] + \": annotation docs\")\n",
    "\n",
    "\n",
    "ad = annotation_docs.copy()\n",
    "\n",
    "for annotation_doc in ad:\n",
    "    elements = annotation_doc['elements']\n",
    "    for element in elements:\n",
    "        element['closed'] = False\n",
    "        element['points'] = element['points'][:-1]\n",
    "\n",
    "# Post the annotation documents you created to the server\n",
    "for annotation_doc in annotation_docs:\n",
    "    resp = conn.post(\n",
    "        \"/annotation?itemId=\" + slide_ids[18], json=annotation_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add points and edges to graph\n",
    "#for simplex in tri_simplices_cut:\n",
    "for simplex in tri.simplices:\n",
    "    \n",
    "    G.add_nodes_from(simplex)\n",
    "    G.add_edge(simplex[0], simplex[1])\n",
    "    G.add_edge(simplex[1], simplex[2])\n",
    "    G.add_edge(simplex[2], simplex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display some stuff about the network\n",
    "print(f'Network has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges')\n",
    "\n",
    "nx.draw(G, node_size=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the separated components in this list\n",
    "components = [c for c in nx.connected_components(G)]\n",
    "print(f'Found {len(components)} connected components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each component on the image\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "for component_idx, component in enumerate(components):\n",
    "    this_component_list = list(component)\n",
    "    this_component_coords = polygon_centroids[this_component_list,:]\n",
    "    this_component_tri = Delaunay(this_component_coords)\n",
    "    this_component_tri_cut = cut_triangles(this_component_tri, tissue_cordinates, verbose=False)\n",
    "\n",
    "    ax.triplot(this_component_coords[:,0], this_component_coords[:,1], this_component_tri_cut)\n",
    "    ax.scatter(tissue_x, tissue_y, c='k')\n",
    "    ax.axis('off')\n",
    "plt.savefig( slide_name + 'Components.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_tissue_polys = []\n",
    "\n",
    "for component in components:\n",
    "    this_component_list = list(component)\n",
    "\n",
    "    # We can't index directly into a multipolygon, so pull them out one at a time\n",
    "    this_component_polys = []\n",
    "    for this_component in this_component_list:\n",
    "        this_component_polys.append(poly_union[this_component])\n",
    "    component_tissue_polys.append(this_component_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply heuristic to this set of polygons\n",
    "def apply_heuristic(tissue_polys):\n",
    "    poly_areas = []\n",
    "    for p in tissue_polys:\n",
    "        poly_areas.append(p.area)\n",
    "    biggest_polygon = np.argmax(poly_areas)\n",
    "    \n",
    "    # Gather up all the coordinates we need\n",
    "    mt_poly = tissue_polys[biggest_polygon]\n",
    "    sat_polys = tissue_polys\n",
    "    del sat_polys[biggest_polygon]\n",
    "    \n",
    "    return mt_poly, sat_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(component_tissue_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_poly, sat_polys = apply_heuristic(component_tissue_polys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the largest polygon \n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(thumbnail_rgb)\n",
    "\n",
    "# Display the mt poly\n",
    "x, y = mt_poly.exterior.xy\n",
    "ax.plot(np.array(x) / width_ratio, np.array(y) / height_ratio, 'r') \n",
    "\n",
    "# Display the sat polys\n",
    "for sat_poly in sat_polys:\n",
    "    x, y = sat_poly.exterior.xy\n",
    "    ax.plot(np.array(x) / width_ratio, np.array(y) / height_ratio, 'b') \n",
    "\n",
    "ax.axis('off')\n",
    "plt.savefig(slide_name + 'Heuristic_WSI.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_bounds_and_centroid(input_poly):\n",
    "    boundaries_x, boundaries_y = input_poly.exterior.xy\n",
    "    boundaries = np.array([[x,y] for x,y in zip(boundaries_x, boundaries_y)])\n",
    "\n",
    "    cent_x,cent_y = input_poly.centroid.xy\n",
    "    centroid = np.array([[x,y] for x,y in zip(cent_x, cent_y)])\n",
    "    return boundaries, centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_boundaries_x, mt_boundaries_y = mt_poly.exterior.xy\n",
    "# mt_boundaries = np.array([[x,y] for x,y in zip(mt_boundaries_x, mt_boundaries_y)])\n",
    "\n",
    "# tum_x,tum_y = mt_poly.centroid.xy\n",
    "# mt_centroid = np.array([[x,y] for x,y in zip(tum_x, tum_y)])\n",
    "mt_boundaries, mt_centroid = get_poly_bounds_and_centroid(mt_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the satellite coordinates to be numpy arrays\n",
    "sat_boundaries = []\n",
    "sat_centroids = np.array([0, 0])\n",
    "\n",
    "for sat_poly in sat_polys:\n",
    "\n",
    "    this_sat_boundaries, this_sat_centroid = get_poly_bounds_and_centroid(sat_poly)\n",
    "    sat_centroids = np.vstack([sat_centroids, this_sat_centroid])\n",
    "    sat_boundaries.append(this_sat_boundaries)\n",
    "    \n",
    "#     x_centroid,y_centroid = sat_poly.centroid.xy\n",
    "#     sat_centroids = np.vstack([sat_centroids, [[x,y] for x,y in zip(x_centroid, y_centroid)]])\n",
    "\n",
    "#     sat_boundaries_x, sat_boundaries_y = sat_poly.exterior.xy\n",
    "#     sat_boundaries.append(np.array([[x,y] for x,y in zip(sat_boundaries_x, sat_boundaries_y)]))\n",
    "\n",
    "sat_centroids = sat_centroids[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_coordinates = np.vstack([tissue_cordinates, mt_boundaries])\n",
    "\n",
    "\n",
    "tri = Delaunay(sat_centroids)\n",
    "tri_simplices_cut = cut_triangles(tri, cut_coordinates)\n",
    "\n",
    "\n",
    "#Check the cutting\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.triplot(sat_centroids[:,0], sat_centroids[:,1], tri_simplices_cut, c='r')\n",
    "ax.scatter(sat_centroids[:,0], sat_centroids[:,1], c='g')\n",
    "ax.scatter(tissue_x, tissue_y, c='k')\n",
    "ax.scatter(mt_boundaries[:,0], mt_boundaries[:,1], c='b')\n",
    "plt.savefig(slide_name  + 'Final_Delaunay.png', dpi=100)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step1) We will loop through each of the slide id and the slide name(as shown below in the for loop)\n",
    "step2) Then we go and process the WSI to get the Slide Thumbnail and detect the tissue boundary\n",
    "Step3) Once we have the tissue boundary, we extract the tissue cordinates\n",
    "Step4) We use these Tissue cordinates to constrcut tissue lines(Your function call it here in the for loop)\n",
    "Step5) Then you go in and check the intersection of the DT with the Tissue lines\n",
    "Step6) If true, delete the lines or the triangles that intersect.\n",
    "Step7) Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through each and every single slide to extract geometry and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of slides\n",
    "for (slide_id, slide_name) in zip(slide_ids, slide_names):\n",
    "    print(f'Processing {slide_name} ({slide_id})')\n",
    "    \n",
    "    # Skip this slide if we already have features extracted\n",
    "    feature_list = glob.glob(os.path.join(feature_dir, slide_name.split('.')[0] + f'*.csv'))\n",
    "    if len(feature_list)>0:\n",
    "        print(f'We already have features for {slide_name}.')\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    \n",
    "    # grab a thumbnail of the image\n",
    "    try:\n",
    "        thumbnail_rgb = get_slide_thumbnail(conn, slide_id)\n",
    "        (thumb_height, thumb_width, _) = np.shape(thumbnail_rgb)\n",
    "    except:\n",
    "        print(f'Could not extract thumbnail for {slide_name}.')\n",
    "        continue\n",
    "    \n",
    "    # Get the connected component labels of the tissue\n",
    "    labeled_proc = detect_tissue_boundary(thumbnail_rgb, threshold = 0.2)\n",
    "\n",
    "    # Grab the x and y coordinates of the tissue regions\n",
    "    tissue_x, tissue_y = get_tissue_coordinates(labeled_proc)\n",
    "    \n",
    "    # Grab the sample height and width, and use these to calculate the resize ratio\n",
    "    try:\n",
    "        slide_info = conn.get(f\"/item/{slide_id}/tiles\")\n",
    "    except:\n",
    "        print(f'Error getting slide info for {slide_id}')\n",
    "        continue\n",
    "    \n",
    "    # Scale the tissue x and y coordinates\n",
    "    height_ratio, width_ratio = get_slide_ratio(slide_info, thumb_height, thumb_width)\n",
    "    \n",
    "    tissue_x = list((width_ratio * tissue_x).astype(int))\n",
    "    tissue_y = list((height_ratio * tissue_y).astype(int))\n",
    "    \n",
    "    tissue_cordinates = [[x,y] for x,y in zip (tissue_x, tissue_y)]\n",
    "\n",
    "    \n",
    "    #This is the point where you need  to add your stuff    #f, ax = plt.subplots(figsize=(5,5))\n",
    "    #ax.scatter(tissue_x, tissue_y)\n",
    "    #ax.axis('off')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Get the elements (slide annotations) from the server\n",
    "    try:\n",
    "        elements, metadata = get_annotations_from_htk(conn, slide_id, group_list=['tumor', 'ai_tumor', 'satellite'])\n",
    "    except:\n",
    "        print(f'Error getting annotations from {slide_name}.')\n",
    "        continue\n",
    "    \n",
    "    # Get the edges of the polygons and merge those which are overlapping\n",
    "    poly_union, polygon_centroids = get_polygon_objects(elements)\n",
    "    if np.shape(polygon_centroids)[0] <= 3:\n",
    "        print(f'Not enough polygon centroids for {slide_name}. Skipping.')\n",
    "        continue\n",
    "\n",
    "    print(\"Shape of the array = \",np.shape(polygon_centroids))\n",
    "    \n",
    "    # Construct DT\n",
    "    tri = Delaunay(polygon_centroids)\n",
    "        \n",
    "    # Cut the branches using tissue boundary coordiantes\n",
    "    tri_simplices_cut = cut_triangles(tri, tissue_cordinates)\n",
    "    \n",
    "#     # Check the cutting\n",
    "#     f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "#     ax.triplot(polygon_centroids[:,0], polygon_centroids[:,1], tri_simplices_cut, c='r')\n",
    "#     ax.scatter(polygon_centroids[:,0], polygon_centroids[:,1], c='g')\n",
    "#     ax.scatter(tissue_x, tissue_y)\n",
    "#     ax.axis('off')\n",
    "#     plt.savefig( name[i] + 'Cut_poly.png', dpi=100)\n",
    "#     plt.show()\n",
    "\n",
    "    #Create a network graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add points and edges to graph\n",
    "    for simplex in tri_simplices_cut:\n",
    "        G.add_nodes_from(simplex)\n",
    "        G.add_edge(simplex[0], simplex[1])\n",
    "        G.add_edge(simplex[1], simplex[2])\n",
    "        G.add_edge(simplex[2], simplex[0])\n",
    "        \n",
    "    # Display some stuff about the network\n",
    "    print(f'Network has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges')\n",
    "    \n",
    "#     nx.draw(G, node_size=1)\n",
    "#     plt.savefig(name[i] + 'Networkx_graph.png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "    # Find the separated components in this list\n",
    "    components = [c for c in nx.connected_components(G)]\n",
    "    print(f'Found {len(components)} connected components')\n",
    "    \n",
    "#     f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "#     for component_idx, component in enumerate(components):\n",
    "#         this_component_list = list(component)\n",
    "#         this_component_coords = polygon_centroids[this_component_list,:]\n",
    "#         this_component_tri = Delaunay(this_component_coords)\n",
    "#         this_component_tri_cut = cut_triangles(this_component_tri, tissue_cordinates, verbose=False)\n",
    "\n",
    "#         ax.triplot(this_component_coords[:,0], this_component_coords[:,1], this_component_tri_cut)\n",
    "\n",
    "#         ax.scatter(tissue_x, tissue_y, c='k')\n",
    "#         ax.axis('off')\n",
    "#         plt.savefig( name[i] + component_idx + 'Separated_components.png', dpi=100)\n",
    "#         plt.show()\n",
    "    \n",
    "    #type(poly_union)\n",
    "\n",
    "    component_tissue_polys = []\n",
    "    max_poly_count = 0\n",
    "    for component in components:\n",
    "        this_component_list = list(component)\n",
    "\n",
    "        # We can't index directly into a multipolygon, so pull them out one at a time\n",
    "        this_component_polys = []\n",
    "        \n",
    "        for this_component in this_component_list:\n",
    "            this_component_polys.append(poly_union[this_component])\n",
    "        component_tissue_polys.append(this_component_polys)\n",
    "        if max_poly_count < len(this_component_polys):\n",
    "            max_poly_count = len(this_component_polys)\n",
    "            \n",
    "        \n",
    "        \n",
    "    for tissue_idx, tissue_polys in enumerate(component_tissue_polys):\n",
    "        if len(tissue_polys) < max_poly_count:\n",
    "            continue\n",
    "        save_name = slide_name + f'_{tissue_idx}.csv'\n",
    "        \n",
    "        mt_poly, sat_polys = apply_heuristic(tissue_polys)\n",
    "                \n",
    "        mt_boundaries, mt_centroid = get_poly_bounds_and_centroid(mt_poly)\n",
    "\n",
    "        # Get satellite boundaries and centroids\n",
    "        sat_boundaries = []\n",
    "        sat_centroids = np.array([0, 0])\n",
    "\n",
    "        for sat_poly in sat_polys:\n",
    "            this_sat_boundaries, this_sat_centroid = get_poly_bounds_and_centroid(sat_poly)\n",
    "            sat_centroids = np.vstack([sat_centroids, this_sat_centroid])\n",
    "            sat_boundaries.append(this_sat_boundaries)\n",
    "        sat_centroids = sat_centroids[1:]\n",
    "        \n",
    "        # Cut the satellites again\n",
    "        cut_coordinates = np.vstack([tissue_cordinates, mt_boundaries])\n",
    "\n",
    "        if len(sat_centroids) < 3:\n",
    "            print(f'{slide_name}, in component {tissue_idx}, has insufficient satellites (only has {len(sat_centroids)}, so skipping')\n",
    "            continue\n",
    "            \n",
    "        tri = Delaunay(sat_centroids)\n",
    "        tri_simplices_cut = cut_triangles(tri, cut_coordinates)\n",
    "\n",
    "                \n",
    "        # Check the cutting\n",
    "#         f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "#         ax.triplot(sat_centroids[:,0], sat_centroids[:,1], tri_simplices_cut, c='r')\n",
    "#         ax.scatter(sat_centroids[:,0], sat_centroids[:,1], c='g')\n",
    "#         ax.scatter(tissue_x, tissue_y, c='k')\n",
    "#         ax.scatter(mt_boundaries[:,0], mt_boundaries[:,1], c='b')\n",
    "#         #plt.savefig(slide_name  + 'Final_Delaunay.png', dpi=100)\n",
    "#         ax.axis('off')\n",
    "#         plt.show()\n",
    "        try:\n",
    "            dt_lengths = get_triangle_lengths(sat_centroids, tri_simplices_cut)\n",
    "            dt_areas = get_triangle_areas(sat_centroids, tri_simplices_cut)\n",
    "            dt_lengths_feats = descriptive_stats(dt_lengths, 'delaunay_length_')\n",
    "            dt_areas_feats = descriptive_stats(dt_areas, 'delaunay_area_')\n",
    "        except:\n",
    "            print(f'{slide_name} has insufficient unique, non-negative simplex cordinates in {tissue_idx}, so skipping')\n",
    "\n",
    "            pass\n",
    "\n",
    "#         # We already have our DT from above\n",
    "#         dt_lengths = get_triangle_lengths(sat_centroids, tri_simplices_cut)\n",
    "#         dt_areas = get_triangle_areas(sat_centroids, tri_simplices_cut)\n",
    "#         dt_lengths_feats = descriptive_stats(dt_lengths, 'delaunay_length_')\n",
    "#         dt_areas_feats = descriptive_stats(dt_areas, 'delaunay_area_')\n",
    "        \n",
    "        sat_surf_distances = []\n",
    "        for sat_bound in sat_boundaries:\n",
    "            sat_surf_distances.append(distance.cdist(sat_bound, mt_boundaries, 'euclidean').min())\n",
    "\n",
    "        sat_surf_distances_features = descriptive_stats(sat_surf_distances, 'sat_surf_distance_')\n",
    "\n",
    "        # Calculate min distances directly from the sat / mt coordinates\n",
    "        sat_centroid_distances = np.amin(distance.cdist(sat_centroids, mt_boundaries, 'euclidean'), axis=1)\n",
    "\n",
    "        #upload distance df\n",
    "        #distance_df = create_distance_dataframe(sat_surf_distances, sat_centroids)\n",
    "\n",
    "        sat_centroid_distances_features = descriptive_stats(sat_centroid_distances, 'sat_absolute_distance_')\n",
    "\n",
    "        # Compute convex hull for satellite boundaries\n",
    "        sat_boundaries_stacked = np.vstack(sat_boundaries)\n",
    "        sat_hull = ConvexHull(sat_boundaries_stacked)\n",
    "        mt_hull = ConvexHull(mt_boundaries)\n",
    "\n",
    "\n",
    "        sat_pct_area = []\n",
    "        for sat_poly in sat_polys:\n",
    "            sat_pct_area.append(sat_poly.area / (sat_hull.volume - mt_hull.volume))\n",
    "        sat_hull_features = descriptive_stats(sat_pct_area, 'sat_hull_pct_area_')\n",
    "\n",
    "        # Convert coordinates to thumbnail-size\n",
    "        mt_boundaries_y = (mt_boundaries[:,0] / height_ratio).astype(int)\n",
    "        mt_boundaries_x = (mt_boundaries[:,1] / width_ratio).astype(int)\n",
    "\n",
    "        # Create the mt binary mask\n",
    "        mt_mask = Image.new('L', (thumb_width, thumb_height), 0)\n",
    "        ImageDraw.Draw(mt_mask).polygon([(x,y) for x,y in zip(mt_boundaries_y, mt_boundaries_x)], outline=1, fill=1)\n",
    "        mt_mask = np.array(mt_mask)\n",
    "\n",
    "        # Convert sat coordinates to thumbnail-size\n",
    "        sat_scaled = []\n",
    "        for sat_boundary in sat_boundaries:\n",
    "            sat_scaled.append(sat_boundary / [width_ratio, height_ratio])\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(10,10))\n",
    "        ax.imshow(mt_mask)\n",
    "        for sat in sat_scaled:\n",
    "            ax.scatter(sat[:,0], sat[:,1])\n",
    "        ax.axis('off')\n",
    "        #plt.savefig(slide_name  + 'Convex_Hull.png', dpi=100)\n",
    "        plt.show()\n",
    "\n",
    "        # Creating satellite wave numbers\n",
    "        sat_wave_number = assign_wave_index(mt_mask, sat_scaled)\n",
    "\n",
    "        #Creating graphs\n",
    "        sat_wave_indices = np.reshape(sat_wave_number, [len(sat_wave_number),])\n",
    "\n",
    "        # Get the list of descending-size arrays\n",
    "        sat_ordering = np.argsort(sat_wave_indices)[::-1]\n",
    "\n",
    "        wave_distances = []\n",
    "\n",
    "        # For each satellite\n",
    "        for sat_idx, sat in enumerate(sat_polys):\n",
    "\n",
    "            # Get the sat boundaries \n",
    "            curr_sat_boundaries = sat_boundaries[sat_idx]\n",
    "\n",
    "            # Get a list of the satellites + mt that have a lower wave index\n",
    "            wave_targets = np.where(sat_wave_indices < sat_wave_indices[sat_idx])\n",
    "            sat_targets = []\n",
    "            for wave_target in wave_targets[0]:\n",
    "                sat_targets.append(sat_polys[wave_target])\n",
    "            sat_targets.append(mt_poly)\n",
    "\n",
    "            # Calculate the distance between this current sat and all targets\n",
    "            sat_target_distances = []\n",
    "            for sat_target in sat_targets:\n",
    "                # Calculate the minimum distance from the surface of the current sat to the surface of the target\n",
    "                target_x, target_y = sat_target.exterior.xy\n",
    "                target_boundaries = np.array([[x,y] for x,y in zip(target_x, target_y)])\n",
    "                sat_target_distances.append(distance.cdist(target_boundaries, curr_sat_boundaries, metric = 'euclidean').min())\n",
    "\n",
    "            # Figure out which target is the closest\n",
    "            closest_target_distance = np.min(np.array(sat_target_distances))\n",
    "            wave_distances.append(closest_target_distance)\n",
    "\n",
    "        wave_features = descriptive_stats(wave_distances, 'wave_distance_')\n",
    "        \n",
    "        features_dataframe = pd.concat([dt_lengths_feats, dt_areas_feats, sat_surf_distances_features, sat_centroid_distances_features, sat_hull_features, wave_features], axis=1)\n",
    "\n",
    "        #save_name = slide_name + f'_{tissue_idx}.csv'\n",
    "\n",
    "        # Set the index of the feature dataframe to be the save-name\n",
    "        features_dataframe['slide_tissue'] = save_name.split('.')[0]\n",
    "        features_dataframe = features_dataframe.set_index('slide_tissue')\n",
    "        #features_dataframe.to_csv(save_dir / save_name)\n",
    "        features_dataframe.to_csv(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Stuff that can be used to visualize the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to upload Features on Histomics\n",
    "The functions below take the different feature values that have been extracted and uploads them on Histomics as a different group which can be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_dataframe(pts1, pts2, group_name='Satellite Distances', color_string='rgb(1,0,0)'):\n",
    "    \"\"\"Takes in two point sets (pts1, pts2) and returns a DSA-style dataframe consisting of the lines between the two.\n",
    "    \"\"\"\n",
    "    group = []\n",
    "    color = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    has_holes = []\n",
    "    touches_edge_top = []\n",
    "    touches_edge_left = []\n",
    "    touches_edge_bottom = []\n",
    "    touches_edge_right = []\n",
    "    coords_x = []\n",
    "    coords_y = []\n",
    "    \n",
    "    assert len(pts1) == len(pts2)\n",
    "    npts = len(pts1)\n",
    "    \n",
    "    for pt_idx in np.arange(npts):\n",
    "        \n",
    "        obj_x = [pts1[pt_idx][0], pts2[pt_idx][0]]\n",
    "        obj_y = [pts1[pt_idx][1], pts2[pt_idx][1]]\n",
    "\n",
    "        # =========\n",
    "        # Possibly need to check that these should be str(int(x)) and str(int(y))?\n",
    "        obj_x_str = ','.join([str(int(x)) for x in obj_x])\n",
    "        obj_y_str = ','.join([str(int(y)) for y in obj_y])\n",
    "        # =========\n",
    "\n",
    "        ymin.append(int(np.min(obj_y)))\n",
    "        xmin.append(int(np.min(obj_x)))\n",
    "        ymax.append(int(np.max(obj_y)))\n",
    "        xmax.append(int(np.max(obj_x)))\n",
    "\n",
    "        coords_x.append(obj_x_str)\n",
    "        coords_y.append(obj_y_str)\n",
    "\n",
    "        # Properties of the overall class group (Delaunay)\n",
    "        group.append(group_name)\n",
    "        color.append(color_string)\n",
    "\n",
    "        has_holes.append(0)\n",
    "        touches_edge_top.append(0)\n",
    "        touches_edge_left.append(0)\n",
    "        touches_edge_bottom.append(0)\n",
    "        touches_edge_right.append(0)\n",
    "\n",
    "    # Put it all into a dataframe\n",
    "    return pd.DataFrame({\n",
    "        'group': group,\n",
    "        'color': color,\n",
    "        'ymin': ymin,\n",
    "        'ymax': ymax,\n",
    "        'xmin': xmin,\n",
    "        'xmax': xmax,\n",
    "        'has_holes': has_holes,\n",
    "        'touches_edge-top': touches_edge_top,\n",
    "        'touches_edge-left': touches_edge_left,\n",
    "        'touches_edge-bottom': touches_edge_bottom,\n",
    "        'touches_edge-right': touches_edge_right,\n",
    "        'coords_x': coords_x,\n",
    "        'coords_y': coords_y\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delaunay_dataframe(nodes, simplices, group_name='Delaunay Triangulation', color_string='rgb(0,0,0)'):\n",
    "    group = []\n",
    "    color = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    has_holes = []\n",
    "    touches_edge_top = []\n",
    "    touches_edge_left = []\n",
    "    touches_edge_bottom = []\n",
    "    touches_edge_right = []\n",
    "    coords_x = []\n",
    "    coords_y = []\n",
    "\n",
    "    for simplex in simplices:\n",
    "        # Grab the coordinates of the triangle\n",
    "        obj_x = nodes[simplex, 0]\n",
    "        obj_y = nodes[simplex, 1]\n",
    "\n",
    "        # =========\n",
    "        # Possibly need to check that these should be str(int(x)) and str(int(y))?\n",
    "        obj_x_str = ','.join([str(int(x)) for x in obj_x])\n",
    "        obj_y_str = ','.join([str(int(y)) for y in obj_y])\n",
    "        # =========\n",
    "\n",
    "        ymin.append(int(np.min(obj_y)))\n",
    "        xmin.append(int(np.min(obj_x)))\n",
    "        ymax.append(int(np.max(obj_y)))\n",
    "        xmax.append(int(np.max(obj_x)))\n",
    "\n",
    "        coords_x.append(obj_x_str)\n",
    "        coords_y.append(obj_y_str)\n",
    "\n",
    "        # Properties of the overall class group (Delaunay)\n",
    "        group.append(group_name)\n",
    "        color.append(color_string)\n",
    "\n",
    "        has_holes.append(0)\n",
    "        touches_edge_top.append(0)\n",
    "        touches_edge_left.append(0)\n",
    "        touches_edge_bottom.append(0)\n",
    "        touches_edge_right.append(0)\n",
    "\n",
    "    # Put it all into a dataframe\n",
    "    return pd.DataFrame({\n",
    "        'group': group,\n",
    "        'color': color,\n",
    "        'ymin': ymin,\n",
    "        'ymax': ymax,\n",
    "        'xmin': xmin,\n",
    "        'xmax': xmax,\n",
    "        'has_holes': has_holes,\n",
    "        'touches_edge-top': touches_edge_top,\n",
    "        'touches_edge-left': touches_edge_left,\n",
    "        'touches_edge-bottom': touches_edge_bottom,\n",
    "        'touches_edge-right': touches_edge_right,\n",
    "        'coords_x': coords_x,\n",
    "        'coords_y': coords_y\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "occ_project",
   "language": "python",
   "name": "occ_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
